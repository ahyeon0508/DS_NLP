{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "threaded-nelson",
   "metadata": {},
   "source": [
    "📖 출처: 텐서플로 2와 머신러닝으로 시작하는 자연어 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "later-final",
   "metadata": {},
   "source": [
    "# 텍스트 유사도(Text Similarity)\n",
    "    - 문장이 유사한지 측정하는 방법\n",
    "    - 유사도를 판단하는 척도는 매우 주관적이기 때문에 데이터를 구성하기가 쉽지 않고 정량화하는 데 한계가 있다  \n",
    "    => 최대한 정량화해서 모델을 만드는 것이 중요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "known-travel",
   "metadata": {},
   "source": [
    "## 유사도를 측정하기 위해 정량화하는 방법\n",
    "    - 단순히 같은 단어의 개수를 사용해서 유사도를 판단하는 방법\n",
    "    - 형태소로 나누어 형태소를 비교하는 방법\n",
    "    - 자소 단위로 나눈어 단어를 비교하는 방법 등등등\n",
    "\n",
    "**단어, 형태소, 유사도의 종류에 상관 없이, 텍스트를 벡터화한 후 벡터화된 각 문장간의 유사도를 측정하는 방법에 대해 공부함**  \n",
    "**주로 쓰이는 유사도 측정 방법 : 자카드 유사도, 유클리디언 유사도, 맨하탄 유사도, 코사인 유사도**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "headed-hacker",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transsexual-private",
   "metadata": {},
   "source": [
    "예시문장\n",
    "- 휴일인 오늘도 서쪽을 중심으로 폭염이 이어졌는데요, 내일은 반가운 비 소식이 있습니다.\n",
    "- 폭염을 피해서 휴일에 놀러왔다가 갑작스런 비로 인해 망연자실하고 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-disclosure",
   "metadata": {},
   "source": [
    "## 단어 벡터화(TF-IDF : Term Frequency - Inverse Document Frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "uniform-sympathy",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'갑작스런': 1.4054651081081644, '내일': 1.4054651081081644, '놀러왔다가': 1.4054651081081644, '망연자실': 1.4054651081081644, '반가운': 1.4054651081081644, '서쪽': 1.4054651081081644, '소식': 1.4054651081081644, '오늘': 1.4054651081081644, '으로': 1.4054651081081644, '이어졌는데요': 1.4054651081081644, '인해': 1.4054651081081644, '있습니다': 1.0, '중심': 1.4054651081081644, '폭염': 1.0, '피해서': 1.4054651081081644, '하고': 1.4054651081081644, '휴일': 1.0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "sentence = (\"휴일 인 오늘 도 서쪽 을 중심 으로 폭염 이 이어졌는데요, 내일 은 반가운 비 소식 이 있습니다.\", \"폭염 을 피해서 휴일 에 놀러왔다가 갑작스런 비 로 인해 망연자실 하고 있습니다.\")\n",
    "\n",
    "# 객체 생성\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# 문장 벡터화 진행\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(sentence)\n",
    "\n",
    "# 각 단어\n",
    "text = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "# 각 단어의 벡터 값\n",
    "idf = tfidf_vectorizer.idf_\n",
    "print(dict(zip(text, idf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scheduled-transport",
   "metadata": {},
   "source": [
    "=> TF-IDF로 벡터화한 값은 자카드 유사도를 제외한 유사도 측정에 모두 사용할 것임.\n",
    "\n",
    "- [비가 나오지 않는 현상](https://github.com/NLP-kr/tensorflow-ml-nlp/issues/13)  \n",
    "sklearn 에 TF-IDF API에서는 한글 한음절 (예: \"비\", \"눈\" 등) 과 알파벳 한개(예: \"a\", \"t\"등) 은 분석 내용에서 포함되지 않아 위와 같은 결과가 발생하고 있으며, API 특성으로 보임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understood-attendance",
   "metadata": {},
   "source": [
    "## 유사도 측정 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contained-participant",
   "metadata": {},
   "source": [
    "### 자카드 유사도(Jaccard Similarity)\n",
    "    - 두 문장을 각각 단어의 집합으로 만든 뒤 두 집합을 통해 유사도를 측정하는 방식 중 하나이다.\n",
    "    - 유사도를 측정하는 방법은 두 집합의 교집합인 공통된 단어의 개수를 두 집합의 합집합 즉, 전체 단어의 개수로 나눈다.\n",
    "    - 결과값은 공통의 원소의 개수에 따라 0고 1사이의 값이 나올 것이고, 1에 가까울수록 유사도가 높다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radical-defendant",
   "metadata": {},
   "source": [
    "### 코사인 유사도(Cosine Similarity)\n",
    "    - 두 개의 벡터값에서 코사인 각도를 구하는 방법이며, 일반적으로 성능이 좋기 때문에 가장 널리 쓰이는 방법 중 하나이다.\n",
    "    - 코사인 유사도 값은 -1과 1사이의 값을 가지고 1에 가까울수록 유사하다는 것을 의미한다.\n",
    "    - 단순히 좌표 상의 거리를 구하는 다른 유사도 측정과 달리 두 벡터의 각도를 구하므로 방향성의 개념이 더해진다.\n",
    "    - 두 문장이 유사하다면 같은 방향을 가리키고, 그렇지 않다면 직교로 표현 될 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "polish-chambers",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.17952266]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 첫 번째와 두 번째 문장 비교\n",
    "print(cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-bradley",
   "metadata": {},
   "source": [
    "### 유클리디언 유사도(Euclidean Distance) or L2 거리(L2-Distance)\n",
    "    - 가장 기본적인 거리를 측정하는 유사도 공식\n",
    "    - 유클리디언 거리 = L2 거리 : N차원 공간에서 두 점 사이의 최단 거리를 구하는 접근법\n",
    "    - 유클리디언 유사도는 단순히 두 점 사이의 거리를 뜻하므로, 1 이상의 값을 가지지 않을 수도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "colonial-rental",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.28099753]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "print(euclidean_distances(tfidf_matrix[0:1], tfidf_matrix[1:2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clean-logic",
   "metadata": {},
   "source": [
    "    - 앞서 구한 벡터를 일반화한 후 다시 유클리디언 유사도를 측정하면 0과 1 사이의 값을 가진다.\n",
    "    - L1 정규화 방법 : 각 벡터안의 요소값을 모두 더한 것의 크기가 1이 되도록 벡터의 크기를 조절하는 방법\n",
    "    즉, 벡터의 모든 값을 더한 뒤, 이 값으로 각 벡터의 값을 나눈다.\n",
    "    - 유클리디언 유사도를 측정할 때는, 편의를 위해 정규화한 후 측정하는 방법도 있다는 점을 기억하자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "brutal-champagne",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.20491229]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def l1_normalize(v):\n",
    "    norm = np.sum(v)\n",
    "    return v / norm\n",
    "\n",
    "tfidf_norm_l1 = l1_normalize(tfidf_matrix)\n",
    "\n",
    "print(euclidean_distances(tfidf_norm_l1[0:1], tfidf_norm_l1[1:2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bound-dinner",
   "metadata": {},
   "source": [
    "### 맨하탄 유사도(Manhattan Similarity) or L1 거리(L1-Distance)\n",
    "    - 사각형 격자로 이뤄진 지도에서 출발점에서 도착점까지를 가로지르지 않고 갈 수 있는 최단거리를 구하는 공식\n",
    "    - 맨하탄 거리 = L1 거리\n",
    "    - 맨하탄 유사도 또한 유클리디언 유사도와 마찬가지로 값이 계속 커질 수 있다.\n",
    "    - 따라서 0과 1사이의 값을 갖도록 L1 정규화 방법을 사용한 벡터 값으로 유사도를 측정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "early-corpus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.77865927]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import manhattan_distances\n",
    "\n",
    "print(manhattan_distances(tfidf_norm_l1[0:1], tfidf_norm_l1[1:2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suburban-bulgarian",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contemporary-blues",
   "metadata": {},
   "source": [
    "## 결론"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conservative-klein",
   "metadata": {},
   "source": [
    "    - 맨하탄 유사도로 측정했을 때 유사도가 가장 높게 나왔다.\n",
    "    - 측정 방법에 따라 크게 유사도가 달라질 수 있으므로 의도하고자 하는 방향에 맞는 유사도 측정 방법을 고르는 것이 매우 중요하다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
